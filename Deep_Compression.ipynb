{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Deep-Compression-Tutorial'...\n",
      "warning: You appear to have cloned an empty repository.\n"
     ]
    }
   ],
   "source": [
    "# Clone git repository\n",
    "!rm -r .*\n",
    "!git clone https://github.com/mujjingun/Deep-Compression-Tutorial ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKt1TfTLFkJ8",
    "tags": []
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XK6CQyo_AD37"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from collections import defaultdict, namedtuple\n",
    "from heapq import heappush, heappop, heapify\n",
    "import struct\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e-Rgi3jVBkOB",
    "tags": []
   },
   "source": [
    "# Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YrzJL9i9BW07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3a38e965c349c9a19f602715bd0b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4b000eb70e4808b36d6aa13108833f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f472e15f2a145d3a37bb9683223df69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766c3e7dbf8147aba91ef592fb64a89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "BATCH_SIZE = 50  # input batch size for training\n",
    "TEST_BATCH_SIZE = 1000  # input batch size for testing\n",
    "\n",
    "# Control Seed\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Loader\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=TEST_BATCH_SIZE, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSS_3wGkB3do"
   },
   "source": [
    "## Training and Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x4blkRo-B2sk"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, learning_rate=0.01, log_interval=10):\n",
    "    # NOTE : `weight_decay` term denotes L2 regularization loss term\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
    "    initial_optimizer_state_dict = optimizer.state_dict()\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                done = batch_idx * len(data)\n",
    "                percentage = 100. * batch_idx / len(train_loader)\n",
    "                pbar.set_description(f'Train Epoch: {epoch} [{done:5}/{len(train_loader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n",
    "\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGj2suo9FnaZ",
    "tags": []
   },
   "source": [
    "# Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XgGn4sX6-RGQ"
   },
   "outputs": [],
   "source": [
    "class LeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 300)\n",
    "        self.fc2 = torch.nn.Linear(300, 100)\n",
    "        self.fc3 = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItxQqVi5A005",
    "outputId": "85c0e3ad-147f-4461-de56-48238457af37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (fc1): Linear(in_features=784, out_features=300, bias=True)\n",
      "  (fc2): Linear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "Total size = 1066440 bytes\n"
     ]
    }
   ],
   "source": [
    "model = LeNet().cuda()\n",
    "model.load_state_dict(torch.load(\"initial_model_statedict.pth\"))\n",
    "\n",
    "print(model)\n",
    "print(f\"Total size = {sum(p.numel() * 4 for p in model.parameters())} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLetBfFFCEfV",
    "outputId": "aef38bd1-50e6-497e-a64d-c29ffdc2f5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1739, Accuracy: 9566/10000 (95.66%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.66"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate initial model performance\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_Bbl6lUCu8S"
   },
   "source": [
    "# Step 1. Modify the Model Code\n",
    "\n",
    "Replace the `torch.nn.Linear` modules in `LeNet` by your custom linear module that applies a binary mask to the weights. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QsXWDiEyDGKP"
   },
   "outputs": [],
   "source": [
    "class MaskedLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MaskedLinear, self).__init__(in_features, out_features, bias)\n",
    "        ##################################################\n",
    "        #                    TODO\n",
    "        # Define `self.mask` which represents a binary mask.\n",
    "        ##################################################\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ##################################################\n",
    "        #                    TODO\n",
    "        # Apply `self.mask` to the weights before \n",
    "        # performing matrix multiplication.\n",
    "        ##################################################\n",
    "        return F.linear(x, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "o44gMSFxJ9i7"
   },
   "outputs": [],
   "source": [
    "class MaskedLeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedLeNet, self).__init__()\n",
    "        ##################################################\n",
    "        #                   TODO\n",
    "        # Replace stock `torch.nn.Linear` with our custom\n",
    "        # `MaskedLinear` module.\n",
    "        ##################################################\n",
    "        self.fc1 = torch.nn.Linear(784, 300)\n",
    "        self.fc2 = torch.nn.Linear(300, 100)\n",
    "        self.fc3 = torch.nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for reporting model size\n",
    "def report_model_size(model, bits_per_weight=32):\n",
    "    print(f\"{'Layer':<15}{'Shape':<15}{'Size (bytes)':<15}{'Original Size (bytes)':<25}{'Size Reduction':<20}\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    total_cur_size = 0\n",
    "    total_orig_size = 0\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, MaskedLinear):\n",
    "            cur_size = module.mask.sum().item()*bits_per_weight/8\n",
    "            orig_size = module.weight.numel()*4\n",
    "            print(f\"{f'{name}.weight':<15}{f'[{module.weight.shape[0]}, {module.weight.shape[1]}]':<15}\"\n",
    "                  f\"{cur_size:<15.0f}{orig_size:<25}\"\n",
    "                  f\"{f'{1-cur_size/orig_size:.4f}%':<20}\")\n",
    "            total_cur_size += cur_size\n",
    "            total_orig_size += orig_size\n",
    "            \n",
    "            cur_size = module.bias.numel()*4\n",
    "            orig_size = module.bias.numel()*4\n",
    "            print(f\"{f'{name}.bias':<15}{f'[{module.bias.shape[0]}]':<15}\"\n",
    "                  f\"{cur_size:<15.0f}{orig_size:<25}\"\n",
    "                  f\"{f'{1-cur_size/orig_size:.4f}%':<20}\")\n",
    "            total_cur_size += cur_size\n",
    "            total_orig_size += orig_size\n",
    "    \n",
    "    print(\"=\"*90)\n",
    "    print(f\"{'Total':<15}{'N/A':<15}{total_cur_size:<15.0f}{total_orig_size:<25}\"\n",
    "          f\"{f'{1-total_cur_size/total_orig_size:.4f}%':<20}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3tKMguTKYx2",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BdMMbi1nKYSY"
   },
   "outputs": [],
   "source": [
    "class MaskedLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MaskedLinear, self).__init__(in_features, out_features, bias)\n",
    "        ##################################################\n",
    "        #                    TODO\n",
    "        # Define `self.mask` which represents a binary mask.\n",
    "        ##################################################\n",
    "        self.mask = torch.ones_like(self.weight).cuda()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ##################################################\n",
    "        #                    TODO\n",
    "        # Apply `self.mask` to the weights before \n",
    "        # performing matrix multiplication.\n",
    "        ##################################################\n",
    "        masked_weight = self.weight * self.mask\n",
    "        return F.linear(x, masked_weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dVDTfpLoKhhP"
   },
   "outputs": [],
   "source": [
    "class MaskedLeNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MaskedLeNet, self).__init__()\n",
    "        ##################################################\n",
    "        #                   TODO\n",
    "        # Replace stock `torch.nn.Linear` with our custom\n",
    "        # `MaskedLinear` module.\n",
    "        ##################################################\n",
    "        self.fc1 = MaskedLinear(784, 300)\n",
    "        self.fc2 = MaskedLinear(300, 100)\n",
    "        self.fc3 = MaskedLinear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.log_softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_1CAzW1KbK6"
   },
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brPSJ4QPKV0i",
    "outputId": "b13df396-8d1a-4ce6-9705-eecd21371f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaskedLeNet(\n",
      "  (fc1): MaskedLinear(in_features=784, out_features=300, bias=True)\n",
      "  (fc2): MaskedLinear(in_features=300, out_features=100, bias=True)\n",
      "  (fc3): MaskedLinear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MaskedLeNet().cuda()\n",
    "model.load_state_dict(torch.load(\"initial_model_statedict.pth\"))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5tO52ogLJ9f",
    "outputId": "e7fc1fdf-5457-4123-b116-d140fec55f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1739, Accuracy: 9566/10000 (95.66%)\n",
      "Layer          Shape          Size (bytes)   Original Size (bytes)    Size Reduction      \n",
      "==========================================================================================\n",
      "fc1.weight     [300, 784]     940800         940800                   0.0000%             \n",
      "fc1.bias       [300]          1200           1200                     0.0000%             \n",
      "fc2.weight     [100, 300]     120000         120000                   0.0000%             \n",
      "fc2.bias       [100]          400            400                      0.0000%             \n",
      "fc3.weight     [10, 100]      4000           4000                     0.0000%             \n",
      "fc3.bias       [10]           40             40                       0.0000%             \n",
      "==========================================================================================\n",
      "Total          N/A            1066440        1066440                  0.0000%             \n"
     ]
    }
   ],
   "source": [
    "# Evaluate initial model performance\n",
    "test(model)\n",
    "report_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "id": "PTAZbJA6MYqP",
    "outputId": "b16a9129-6fcf-41c0-d758-1c577cc325a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2938b71250>"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 750x450 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize weight distribution\n",
    "plt.figure(figsize=(5, 3), dpi=150)\n",
    "plt.yscale('log')\n",
    "\n",
    "weights = model.fc1.weight.data.flatten().cpu()\n",
    "\n",
    "plt.hist(weights, bins=100, range=(-.5, .5), label='fc1 weights')\n",
    "\n",
    "std = torch.std(weights) * 2\n",
    "weights_below_threshold = weights[abs(weights) < std]\n",
    "\n",
    "plt.hist(weights_below_threshold, bins=100, range=(-.5, .5), label='below threshold')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AnBqa27SLZs0"
   },
   "source": [
    "# Step 2. Pruning\n",
    "\n",
    "Set the value of each module's `mask` to 0 wherever the absolute value of the corresponding weight does not exceed the threshold.\n",
    "\n",
    "The threshold value is computed by `sensitivity * (standard deviation of layer weights)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oji7RaeQWFth"
   },
   "outputs": [],
   "source": [
    "def prune_by_std(model, sensitivity=2.0):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, MaskedLinear):\n",
    "            #####################################\n",
    "            #               TODO\n",
    "            # Compute threshold\n",
    "            #####################################\n",
    "            threshold = # TODO\n",
    "\n",
    "            #####################################\n",
    "            #               TODO\n",
    "            # Compute new mask\n",
    "            #####################################\n",
    "            new_mask = # TODO\n",
    "\n",
    "            #####################################\n",
    "            #               TODO\n",
    "            # Copy new mask back to `module.mask`\n",
    "            #####################################\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWIrZGwOWGPL",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "W_mSWCKALdYi"
   },
   "outputs": [],
   "source": [
    "def prune_by_std(model, sensitivity=2.0):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, MaskedLinear):\n",
    "            #####################################\n",
    "            #               TODO\n",
    "            # Compute threshold\n",
    "            #####################################\n",
    "            std = torch.std(module.weight.data)\n",
    "            threshold = std * sensitivity\n",
    "\n",
    "            #####################################\n",
    "            #               TODO\n",
    "            # Compute new mask\n",
    "            #####################################\n",
    "            new_mask = torch.where(\n",
    "                abs(module.weight) < threshold, \n",
    "                torch.zeros_like(module.mask), \n",
    "                module.mask\n",
    "            )\n",
    "\n",
    "            #####################################\n",
    "            #               TODO\n",
    "            # Apply new mask to `module.mask`\n",
    "            #####################################\n",
    "            module.mask.copy_(new_mask)\n",
    "            module.weight.data.copy_(module.weight.data * new_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAg4utEqWfW6"
   },
   "source": [
    "### Call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "YwK7K39bMOR9"
   },
   "outputs": [],
   "source": [
    "prune_by_std(model, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6O7vRvYRD9V",
    "outputId": "f4d5694f-c3d6-49f6-c250-15f292a80cf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.0589, Accuracy: 7542/10000 (75.42%)\n",
      "Layer          Shape          Size (bytes)   Original Size (bytes)    Size Reduction      \n",
      "==========================================================================================\n",
      "fc1.weight     [300, 784]     41904          940800                   0.9555%             \n",
      "fc1.bias       [300]          1200           1200                     0.0000%             \n",
      "fc2.weight     [100, 300]     5100           120000                   0.9575%             \n",
      "fc2.bias       [100]          400            400                      0.0000%             \n",
      "fc3.weight     [10, 100]      328            4000                     0.9180%             \n",
      "fc3.bias       [10]           40             40                       0.0000%             \n",
      "==========================================================================================\n",
      "Total          N/A            48972          1066440                  0.9541%             \n"
     ]
    }
   ],
   "source": [
    "# Evaluate initial model performance\n",
    "test(model)\n",
    "report_model_size(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ReLOMLPYMnu"
   },
   "source": [
    "### Retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5GmqV6fYOit",
    "outputId": "89617945-3c29-48a2-824c-47740a45fc17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [59500/60000 ( 99%)]  Loss: 0.271104: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:08<00:00, 143.74it/s]\n",
      "Train Epoch: 1 [59500/60000 ( 99%)]  Loss: 0.071051: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:07<00:00, 153.23it/s]\n",
      "Train Epoch: 2 [59500/60000 ( 99%)]  Loss: 0.275658: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:08<00:00, 147.18it/s]\n",
      "Train Epoch: 3 [59500/60000 ( 99%)]  Loss: 0.069647: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:07<00:00, 150.68it/s]\n",
      "Train Epoch: 4 [59500/60000 ( 99%)]  Loss: 0.292258: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1200/1200 [00:07<00:00, 152.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dl61oZNzafku",
    "outputId": "1284d765-82a6-4ca1-dce8-9c796cffc864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1153, Accuracy: 9662/10000 (96.62%)\n",
      "Layer          Shape          Size (bytes)   Original Size (bytes)    Size Reduction      \n",
      "==========================================================================================\n",
      "fc1.weight     [300, 784]     41904          940800                   0.9555%             \n",
      "fc1.bias       [300]          1200           1200                     0.0000%             \n",
      "fc2.weight     [100, 300]     5100           120000                   0.9575%             \n",
      "fc2.bias       [100]          400            400                      0.0000%             \n",
      "fc3.weight     [10, 100]      328            4000                     0.9180%             \n",
      "fc3.bias       [10]           40             40                       0.0000%             \n",
      "==========================================================================================\n",
      "Total          N/A            48972          1066440                  0.9541%             \n"
     ]
    }
   ],
   "source": [
    "test(model)\n",
    "report_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "ObtiFFVN58Sw"
   },
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "torch.save({\n",
    "    'state_dict': model.state_dict(),\n",
    "    'mask1': model.fc1.mask,\n",
    "    'mask2': model.fc2.mask,\n",
    "    'mask3': model.fc3.mask\n",
    "}, \"pruned_model_statedict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIZqRptJXSfh"
   },
   "source": [
    "# Step 3. Quantization\n",
    "\n",
    "Hint: use the `csr_matrix` function to convert between sparse weights and dense weights.\n",
    "Note: You need to convert the PyTorch tensor to Numpy array first.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "mat = np.array([[0, 0, 1], [0, 2, 0]])\n",
    "mat = csr_matrix(mat)\n",
    "\n",
    "# Extract only the nonzero elements\n",
    "mat.data  # Output: array([1, 2])\n",
    "\n",
    "# Assign to the nonzero elements of `mat`\n",
    "mat.data = np.array([3, 4])\n",
    "\n",
    "# Convert back to dense representation\n",
    "mat = mat.toarray()  # Output: array([[0, 0, 3], [0, 4, 0]])\n",
    "```\n",
    "\n",
    "Hint2: Use the `Kmeans` function to cluster similar weights together.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(np.array([[10], [1], [2], [11], [12], [3]]))\n",
    "\n",
    "# Obtain the center values of each cluster\n",
    "kmeans.cluster_centers_  # Output: array([2, 11])\n",
    "\n",
    "# Obtain which cluster each element belongs to\n",
    "kmeans.labels_  # Output: array([1, 0, 0, 1, 1, 0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tNTJnQ51ams6"
   },
   "outputs": [],
   "source": [
    "def quantize_weights(model, bits=5):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, MaskedLinear):\n",
    "            weight = (module.weight.data * module.mask).cpu().numpy()\n",
    "            \n",
    "            ########################################\n",
    "            #                 TODO\n",
    "            # Quantize each weight of the module\n",
    "            # with the specified number of bits\n",
    "            ########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzsnWVRtBuX1",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "p6K4vZxMBtuO"
   },
   "outputs": [],
   "source": [
    "def quantize_weights(model, bits=5):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, MaskedLinear):\n",
    "            weight = (module.weight.data * module.mask).cpu().numpy()\n",
    "            \n",
    "            mat = csr_matrix(weight)\n",
    "\n",
    "            kmeans = KMeans(n_clusters=2**bits)\n",
    "            kmeans.fit(mat.data.reshape(-1,1))\n",
    "\n",
    "            new_weight = kmeans.cluster_centers_[kmeans.labels_].reshape(-1)\n",
    "            mat.data = new_weight\n",
    "            module.weight.data.copy_(torch.from_numpy(mat.toarray()).cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSgXsyzlCWA7"
   },
   "source": [
    "### Call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jiFhxCO9CHUQ",
    "outputId": "85b285b1-a86e-4fce-f095-78abdf0ee200"
   },
   "outputs": [],
   "source": [
    "# Load checkpoint from step 1 (optional)\n",
    "ckpt = torch.load(\"pruned_model_statedict.pth\")\n",
    "model.load_state_dict(ckpt['state_dict'])\n",
    "model.fc1.mask.copy_(ckpt['mask1'])\n",
    "model.fc2.mask.copy_(ckpt['mask2'])\n",
    "model.fc3.mask.copy_(ckpt['mask3']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "s_DtlCFWdPeq"
   },
   "outputs": [],
   "source": [
    "quantize_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3qjxyRBlmr6",
    "outputId": "c08586e4-5755-45a1-e8ec-7d0403eb6fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.1153, Accuracy: 9662/10000 (96.62%)\n",
      "Layer          Shape          Size (bytes)   Original Size (bytes)    Size Reduction      \n",
      "==========================================================================================\n",
      "fc1.weight     [300, 784]     6548           940800                   0.9930%             \n",
      "fc1.bias       [300]          1200           1200                     0.0000%             \n",
      "fc2.weight     [100, 300]     797            120000                   0.9934%             \n",
      "fc2.bias       [100]          400            400                      0.0000%             \n",
      "fc3.weight     [10, 100]      51             4000                     0.9872%             \n",
      "fc3.bias       [10]           40             40                       0.0000%             \n",
      "==========================================================================================\n",
      "Total          N/A            9036           1066440                  0.9915%             \n"
     ]
    }
   ],
   "source": [
    "# Evaluate quantized model performance\n",
    "test(model)\n",
    "report_model_size(model, bits_per_weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "8eo11Vqi6a1t"
   },
   "outputs": [],
   "source": [
    "# Save checkpoint\n",
    "torch.save({\n",
    "    'state_dict': model.state_dict(),\n",
    "    'mask1': model.fc1.mask,\n",
    "    'mask2': model.fc2.mask,\n",
    "    'mask3': model.fc3.mask\n",
    "}, \"quantized_model_statedict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9dOKFif6fpA"
   },
   "source": [
    "# Step 4. Huffman Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KOSRyr-kH86D",
    "outputId": "2961ad6d-21cb-40f6-a112-bb7cb6c6254f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer           |   original compressed improvement percent\n",
      "----------------------------------------------------------------------\n",
      "fc1.weight      |      85012      20284       4.19x  23.86%\n",
      "fc1.bias        |       1200       1200       1.00x 100.00%\n",
      "fc2.weight      |      10604       3079       3.44x  29.04%\n",
      "fc2.bias        |        400        400       1.00x 100.00%\n",
      "fc3.weight      |        700        443       1.58x  63.29%\n",
      "fc3.bias        |         40         40       1.00x 100.00%\n",
      "----------------------------------------------------------------------\n",
      "total           |      97956      25446       3.85x  25.98%\n",
      "Loading Huffman coded model\n",
      "Testing\n",
      "Test set: Average loss: 0.1153, Accuracy: 9662/10000 (96.62%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96.62"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huffman import huffman_encode_model, huffman_decode_model\n",
    "\n",
    "huffman_encode_model(model)\n",
    "\n",
    "print(\"Loading Huffman coded model\")\n",
    "huffman_decode_model(model)\n",
    "\n",
    "print(\"Testing\")\n",
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZJcUBptAHtE",
    "outputId": "dfec98af-8b10-43d4-f316-f44d4d0e0e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31075\tencodings\n"
     ]
    }
   ],
   "source": [
    "# Check saved file size (in bytes)\n",
    "!du -b encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MJotPqxAixf",
    "outputId": "9370bdc8-2769-4b57-a14a-236c20594801"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9708609954615356"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate reduction in size\n",
    "# You should get around 97% reduction\n",
    "1 - 31075 / 1066440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wmlviV1dBWNz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "DKt1TfTLFkJ8",
    "e-Rgi3jVBkOB",
    "FGj2suo9FnaZ",
    "a3tKMguTKYx2",
    "AnBqa27SLZs0",
    "lWIrZGwOWGPL",
    "xIZqRptJXSfh",
    "nzsnWVRtBuX1"
   ],
   "name": "Deep Compression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
